Automatically generated by Mendeley Desktop 1.13.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Jylanki2010,
author = {Jyl\"{a}nki, J},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/RectangleBinPack.pdf:pdf},
journal = {Retrived From Http://Clb. Demon. Fi/Files/ \ldots},
keywords = {heuristic algo-,np-hard,on-line algorithm,optimization,rithm,two-dimensional bin packing},
pages = {1--50},
title = {{A thousand ways to pack the bin-a practical approach to two-dimensional rectangle bin packing}},
url = {http://clb.demon.fi/files/RectangleBinPack.pdf},
year = {2010}
}
@article{Lin2013,
author = {Lin, Cheng-Tso},
file = {:C$\backslash$:/Users/Jan-Philip/Downloads/cis565paper.pdf:pdf},
journal = {Journal of Computer Graphics Techniques},
keywords = {SVOGI,Sparse Voxel Octree},
mendeley-tags = {SVOGI,Sparse Voxel Octree},
title = {{Implementing Sparse Voxel Octree}},
year = {2013}
}
@article{Medientechnik2012,
author = {Medientechnik, Bachelorarbeit},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/Globale-Beleuchtung-mit-Cascaded-Light-Propagation-Volumes-in-Echtzeit.pdf:pdf},
title = {{Globale Beleuchtung mit Cascaded Light Propagation Volumes in Echtzeit Realtime Global Illumination with Cascaded Light Propagation Volumes}},
year = {2012}
}
@article{Czaplicki2012,
author = {Czaplicki, Evan},
file = {:D$\backslash$:/Google Drive/Paper/concurrent\_fpr\_for\_functional\_gui\_Czaplicki.pdf:pdf},
number = {March},
pages = {55},
title = {{Elm: Concurrent FRP for Functional GUIs}},
year = {2012}
}
@article{Houlmann,
abstract = {Today, real-time 3d rendering applications are visually more impressive$\backslash$nthan before. Thanks to the hardware evolution which allows developers$\backslash$nand artists to produce incredible effects.$\backslash$n$\backslash$n$\backslash$nHigh Dynamic Range Rendering is a set of techniques that emerge two$\backslash$nyears ago in some video games like Half-Life 2: Lost Coast or Oblivion.$\backslash$nIt was not possible to use real HDR rendering before due to GPU limitations.$\backslash$n$\backslash$n$\backslash$nIn this document, we will expose what is HDR and how can it be used$\backslash$nin real time rendering. The OpenGL project associated with this article$\backslash$nwill demonstrate the use of various HDR effects.},
author = {Houlmann, Fabien and Metz, Stephane},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/HDRRenderingInOpenGL.pdf:pdf},
journal = {Universite de technologie Belfort-Montbeliard},
title = {{High Dynamic Range Rendering in OpenGL}}
}
@article{Magnusson2011,
author = {Magnusson, Kenny},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/GDC11\_LightingYouUpInBattlefield3.pdf:pdf},
journal = {Gdc 2011},
title = {{Lighting you up in Battlefield 3}},
year = {2011}
}
@article{Crassin2011,
abstract = {Indirect illumination is an important element for realistic image synthesis, but its computation is expensive and highly dependent on the complexity of the scene and of the BRDF of the involved surfaces. While off-line com- putation and pre-baking can be acceptable for some cases, many applications (games, simulators, etc.) require real-time or interactive approaches to evaluate indirect illumination. We present a novel algorithm to compute indirect lighting in real-time that avoids costly precomputation steps and is not restricted to low-frequency illumi- nation. It is based on a hierarchical voxel octree representation generated and updated on the fly from a regular scene mesh coupled with an approximate voxel cone tracing that allows for a fast estimation of the visibility and incoming energy. Our approach can manage two light bounces for both Lambertian and glossy materials at in- teractive framerates (25-70FPS). It exhibits an almost scene-independent performance and can handle complex scenes with dynamic content thanks to an interactive octree-voxelization scheme. In addition, we demonstrate that our voxel cone tracing can be used to efficiently estimate Ambient Occlusion.},
author = {Crassin, Cyril and Neyret, Fabrice and Sainz, Miguel and Green, Simon and Eisemann, Elmar},
doi = {10.1111/j.1467-8659.2011.02063.x},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/GIVoxels\_Siggraph\_Talk.pdf:pdf},
isbn = {9781450309745},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {cone-tracing,final gather,global illumination,gpu,indirect lighting,real-time rendering,voxels},
pages = {1921--1930},
title = {{Interactive Indirect Illumination Using Voxel Cone Tracing}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2011.02063.x$\backslash$nhttps://research.nvidia.com/publication/interactive-indirect-illumination-using-voxel-cone-tracing},
volume = {30},
year = {2011}
}
@article{Martin2012,
abstract = {The Elemental demo was developed to demonstrate the capabilities and drive the development of the new Unreal Engine 4. In this talk we want to present some technical details on our implementation of the UE4 rendering features, along with the goals that shape them. Starting with the Unreal Engine3 code major changes to the rendering internals have been implemented. The real-time demo takes per pixel deferred shading to the next level: Light emitters can be image based light sources, area point lights or emissive materials. Our new light transport method based on voxel cone tracing supports dynamic and static geometry and it shines when it comes to glossy materials. Lighting affects both opaque and translucent materials, subsurface scattering and deferred decals. The lighting is complemented by the new GPU accelerated particle simulation and the new post processing pipeline.},
author = {Martin, Mittring},
file = {:D$\backslash$:/Google Drive/Paper/The\_Technology\_Behind\_the\_Elemental\_Demo\_16x9-1248544805.pdf:pdf},
journal = {Acm Siggraph 2012},
title = {{The Technology Behind the “ Unreal Engine 4 Elemental demo ”}},
year = {2012}
}
@article{Lazarov2011,
author = {Lazarov, Dimitar and Engineer, Lead Graphics},
file = {:D$\backslash$:/Google Drive/Paper/s2013\_Physically\_Based\_Shading\_black\_ops\_2\_notes.pdf:pdf},
journal = {Acm Siggraph 2013},
title = {{Summary of Physically Based Shading in Call of Duty : Black Ops}},
year = {2011}
}
@article{Donzallaz2013,
author = {Donzallaz, Pierre-yves and Sousa, Tiago},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/fmx2013\_c3\_art\_tech\_donzallaz\_sousa.pdf:pdf},
title = {{The Art and Technology behind Crysis 3}},
year = {2013}
}
@article{Jarosz2009,
author = {Jarosz, Wojciech and Carr, N a and Jensen, H W},
doi = {10.1111/j.1467-8659.2009.01398.x},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/importance\_sampling\_spherical\_harmonics.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
number = {2},
pages = {577--586},
title = {{Importance sampling spherical harmonics}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01398.x/full},
volume = {28},
year = {2009}
}
@article{Crassin2011a,
abstract = {Indirect illumination is an important element for realistic image synthesis, but its computation is expensive and highly dependent on the complexity of the scene and of the BRDF of the involved surfaces. While off-line com- putation and pre-baking can be acceptable for some cases, many applications (games, simulators, etc.) require real-time or interactive approaches to evaluate indirect illumination. We present a novel algorithm to compute indirect lighting in real-time that avoids costly precomputation steps and is not restricted to low-frequency illumi- nation. It is based on a hierarchical voxel octree representation generated and updated on the fly from a regular scene mesh coupled with an approximate voxel cone tracing that allows for a fast estimation of the visibility and incoming energy. Our approach can manage two light bounces for both Lambertian and glossy materials at in- teractive framerates (25-70FPS). It exhibits an almost scene-independent performance and can handle complex scenes with dynamic content thanks to an interactive octree-voxelization scheme. In addition, we demonstrate that our voxel cone tracing can be used to efficiently estimate Ambient Occlusion.},
author = {Crassin, Cyril and Neyret, Fabrice and Sainz, Miguel and Green, Simon and Eisemann, Elmar},
doi = {10.1111/j.1467-8659.2011.02063.x},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/GIVoxels-pg2011-authors.pdf:pdf},
isbn = {9781450309745},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {cone-tracing,final gather,global illumination,gpu,indirect lighting,real-time rendering,voxels},
number = {7},
pages = {1921--1930},
title = {{Interactive Indirect Illumination Using Voxel Cone Tracing}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2011.02063.x$\backslash$nhttps://research.nvidia.com/publication/interactive-indirect-illumination-using-voxel-cone-tracing},
volume = {30},
year = {2011}
}
@article{Lee,
author = {Lee, Mark},
file = {:D$\backslash$:/Google Drive/Paper/GDC09\_Lee\_Prelighting.pdf:pdf},
title = {{Pre-lighting in Resistance 2}}
}
@article{Martin2010,
author = {Martin, Sam and Einarsson, Per},
file = {:D$\backslash$:/Google Drive/Paper/enlighten\_geometrics\_radiosity\_architecture.pdf:pdf},
pages = {1--35},
title = {{A Real Time Radiosity Architecture}},
year = {2010}
}
@article{Laine2010,
abstract = {In this paper we examine the possibilities of using voxel representations as a generic way for expressing complex and feature-rich geometry on current and future GPUs. We present in detail a compact data structure for storing voxels and an efficient algorithm for performing ray casts using this structure. We augment the voxel data with novel contour information that increases geometric resolution, allows more compact encoding of smooth surfaces, and accelerates ray casts. We also employ a novel normal compression format for storing high-precision object-space normals. Finally, we present a variable-radius post-process filtering technique for smoothing out blockiness caused by discrete sampling of shading attributes. Based on benchmark results, we show that our voxel representation is competitive with triangle-based representations in terms of ray casting performance, while allowing tremendously greater geometric detail and unique shading information for every voxel.},
author = {Laine, Samuli},
doi = {10.1109/TVCG.2010.240},
file = {:D$\backslash$:/Google Drive/Paper/efficient\_sparse\_voxel\_octree\_laine2010tr1\_paper.pdf:pdf},
isbn = {9781605589398},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {February},
pages = {1--30},
pmid = {21041879},
title = {{Efficient Sparse Voxel Octrees – Analysis , Extensions , and Implementation}},
volume = {d},
year = {2010}
}
@article{Bilas2002,
abstract = {A Data-Driven Game Object System with comments},
author = {Bilas, S and Bilas, By Scott},
file = {:D$\backslash$:/Google Drive/Paper/data-driven-game-object-system.pdf:pdf},
journal = {Game Developers Conference Proceedings},
title = {{A data-driven game object system}},
url = {http://gamedevs.org/uploads/data-driven-game-object-system.pdf$\backslash$nhttp://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract},
year = {2002}
}
@article{Olsson2014,
abstract = {Recently, several algorithms have been introduced that enable real- time performance for many lights in applications such as games. In this paper, we explore the use of hardware-supported virtual cube- map shadows to efficiently implement high-quality shadows from hundreds of light sources in real time and within a bounded memory footprint. In addition, we explore the utility of ray tracing for shad- ows from many lights and present a hybrid algorithm combining ray tracing with cube maps to exploit their respective strengths. Our solution supports real-time performance with hundreds of lights in fully dynamic high-detail scenes.},
author = {Olsson, Ola and Sintorn, Erik and K\"{a}mpe, Viktor and Billeter, Markus and Assarsson, Ulf},
doi = {10.1145/2556700.2556701},
file = {:C$\backslash$:/Users/Jan-Philip/Downloads/clustered\_with\_shadows\_siggraph\_2014.pdf:pdf},
isbn = {9781450327176},
journal = {Proceedings of the 18th meeting of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games - I3D '14},
keywords = {a flat look,as light may,but tend to yield,cube map,details in geometry,glecting shadowing makes them,if care is not,leak through walls and,more difficult to use,moreover,ne-,real-time,shadows,similar occluding geometry,virtual},
pages = {87--96},
title = {{Efficient virtual shadow maps for many lights}},
url = {http://dl.acm.org/citation.cfm?doid=2556700.2556701},
year = {2014}
}
@article{Favera2012,
abstract = {Ambient occlusion is a low-cost technique to simulate indirect ambient illumination in a realistic way. The goal is to estimate the amount of incident ambient light at each visible point. In this paper, we propose a novel ambient occlusion method that produces good quality results in real time. Using an efficient voxelization algorithm, we create a volumetric description of the scene geometry in a regular grid. During scene rendering, the hemisphere around each visible point is sampled by a set of cones, each one representing a package of rays. The volume of each cone is sampled by a series of spheres. The obstructed volumes of the spheres are used to estimate the amount of rays that are blocked by the scene geometry. The final ambient occlusion at each visible point is computed by considering all cones in the hemisphere. This approach has shown to be quite adequate: the intersection of each sphere with the voxelized scene is performed in a very efficient manner, and good quality results are achieved with a small number of cones. Computational experiments demonstrate the efficiency and effectiveness of our proposal.},
author = {Favera, Eduardo Ceretta Dalla and Celes, Waldemar},
doi = {10.1109/SIBGRAPI.2012.28},
file = {:C$\backslash$:/Users/Jan-Philip/Downloads/Ambient occlusion using cone tracing with scene voxelization.pdf:pdf},
isbn = {9780769548296},
issn = {15301834},
journal = {Brazilian Symposium of Computer Graphic and Image Processing},
keywords = {Ambient occlusion,cone tracing,global ilumination},
pages = {142--149},
title = {{Ambient occlusion using cone tracing with scene voxelization}},
year = {2012}
}
@article{Dimitrov2007,
author = {Dimitrov, Rouslan},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/cascaded\_shadow\_maps.pdf:pdf},
journal = {Developer Documentation, NVIDIA Corp},
number = {August},
title = {{Cascaded shadow maps}},
url = {http://www.cse.chalmers.se/edu/year/2011/course/TDA361/Advanced Computer Graphics/cascaded\_shadow\_maps.pdf},
year = {2007}
}
@article{Crassin,
author = {Crassin, Cyril},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/SB134-Voxel-Cone-Tracing-Octree-Real-Time-Illumination.pdf:pdf},
title = {{Voxel Cone Tracing and Sparse Voxel Octree for Real-time Global Illumination}}
}
@article{ValveCorporation2012,
abstract = {A fearless adventure in knowing what to do when no one’s there telling you what to do.},
author = {{Valve Corporation}},
file = {:D$\backslash$:/Google Drive/Paper/Valve\_Handbook\_LowRes.pdf:pdf},
journal = {Valve Corporation},
title = {{Handbook for New Employees}},
url = {http://www.valvesoftware.com/company/valve\_handbook\_lowres.pdf},
year = {2012}
}
@article{Samet2009,
author = {Samet, Hanan},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/lath-slides.pdf:pdf},
pages = {1--15},
title = {{Vertex-Based ( Lath ) Representations for Three-Dimensional Objects and Meshes Vertex-based Data Structures}},
year = {2009}
}
@article{Burley2012,
abstract = {Following our success with physically-based hair shading on Tangled [27], we began considering physically- based shading models for a broader range of materials. With the physically-based hair model, we were able to achieve a great degree of visual richness while maintaining artistic control. However, it proved challenging to integrate the lighting of the hair with the rest of the scene which had still used tradi- tional “ad-hoc” shading models and punctual lights. For subsequent films we wanted to increase the richness of all of our materials while making lighting responses more consistent between materials and environments and also wanted to improve artist productivity through the use of simplified controls. When we began our investigation it wasn’t obvious which models to use or even how physically- based we wanted to be. Should we be perfectly energy conserving? Should we favor physical parameters like index-of-refraction? For diffuse, Lambert seemed to be the accepted norm, while specular seemed to get most of the attention in the literature. Some models such as Ashikhmin-Shirley (2000) [3] aimed to be intuitive and practical while physically plausible, while others such as He et al. (1991) [12] provided a more comprehensive physical model. Still others aimed at improved data fitting [15, 14, 22, 17, 4], but few of these are appropriate for direct manipulation. We could have implemented several models and let the artists choose and combine them, but then we’d have been back to the parameter explosion we were trying to get away from. One study of a large variety of measured materials was Ngan et al. (2005) [21] which compared five popular models. Some models fared better than others overall, but interestingly, there was a strong correlation between the models’ performances – some materials were well represented by all the models, and for others, no model proved suitable. Adding an additional specular lobe helped in only a few of the cases. This begs the question, what is not being represented in the difficult materials? To answer this question and to evaluate BRDF models more intuitively we developed a new BRDF viewer that could display and compare both measured and analytic BRDFs. We discovered new, intu- itive ways to view measured BRDF data and we found interesting features in the measured materials that weren’t well-represented by known models. In these course notes we will share observations from studying measured materials along with insights we’ve gleaned about which models fit the measured data and where they fall short. We will then present our new model which is now being used on all current productions. We will also describe our experience of adopting this new model in production and discuss how we were able to add the right level of artistic control while preserving simplicity and robustness.},
author = {Burley, Brent and WaltDisneyAnimationStudios},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/s2012\_pbs\_disney\_brdf\_notes\_v2.pdf:pdf},
journal = {Acm Siggraph},
pages = {1--26},
title = {{Physically-based shading at disney}},
url = {http://disney-animation.s3.amazonaws.com/library/s2012\_pbs\_disney\_brdf\_notes\_v2.pdf},
year = {2012}
}
@article{Kaplanyan2009,
abstract = {This chapter introduces a new technique for approximating the first bounce of diffuse global illumination in real-time. As diffuse global illumination is very computationally intensive, it is usually implemented only as static precomputed solutions thus negatively affecting game production time. In this chapter we present a completely dynamic solution using spherical harmonics (SH) radiance volumes for light field finite-element approximation, point-based injective volumetric rendering and a new iterative radiance propagation approach. Our implementation proves that it is possible to use this solution efficiently even with current generation of console hardware (Microsoft Xbox 360, Sony PlayStation 3). Because this technique does not require any preprocessing stages and fully supports dynamic lighting, objects, materials and view points, it is possible to harmoniously integrate it into an engine as complex as the cross-platform engine CryEngine 3 with a large set of graphics technologies without requiring additional production time. Additional applications and combinations with existing techniques are dicussed in details in this chapter.},
author = {Kaplanyan, Anton},
doi = {10.1.1.154.6436},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/Crytek\_Light\_Propagation\_Volumes.pdf:pdf},
isbn = {9781605589398},
journal = {Advances},
pages = {99--107},
title = {{Light Propagation Volumes in CryEngine 3}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.6436\&amp;rep=rep1\&amp;type=pdf},
year = {2009}
}
@article{Crassin2012,
abstract = {Discrete voxel representations are generating growing interest in a wide range of applications in computational sciences and particularly in computer graphics. In this chapter, we ?rst describe an efficient OpenGL implementation of a simple surface voxelization algorithm that produces a regular 3D texture. This technique uses the GPU hardware rasterizer and the new image load/store interface exposed by OpenGL 4.2. The first part of this chapter will allow to familiarize the reader with the general algorithm and the new OpenGL features we leverage. In the second part we describe an extension of this approach, which enables building and updating a sparse voxel representation in the form of an octree structure. In order to scale to very large scenes, our approach avoids relying on an intermediate full regular grid to build the structure and constructs the octree directly. This second approach exploits the draw indirect features standardized in OpenGL 4.0 in order to allow synchronization-free launching of shader threads during the octree construction, as well as the new atomic counter functions exposed in OpenGL 4.2.},
author = {Crassin, Cyril and Green, Simon},
doi = {10.1201/b12288},
file = {:D$\backslash$:/Google Drive/Paper/OpenGLInsights-SparseVoxelization.pdf:pdf},
isbn = {978-1439893760},
journal = {OpenGL Insights},
pages = {304--319},
title = {{Octree-Based Sparse Voxelization Using The GPU Hardware Rasterizer}},
url = {http://www.seas.upenn.edu/~pcozzi/OpenGLInsights/OpenGLInsights-SparseVoxelization.pdf},
year = {2012}
}
@article{Nvidia2004,
author = {Nvidia},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/Texture\_Atlas\_Whitepaper.pdf:pdf},
journal = {Update},
number = {July},
title = {{Improving Batching Using Texture Atlasing}},
year = {2004}
}
@article{Green2003,
abstract = {Spherical Harmonic lighting (SH lighting) is a technique for calculating the lighting on 3D models from area light sources that allows us to capture, relight and display global illumination style images in real time. It was introduced in a paper at Siggraph 2002 by Sloan, Kautz and Snyder as a technique for ultra realistic lighting of models. Looking a little closer at it’s derivation we can show that it is in fact a toolbox of interrelated techniques that the games community can use to good effect. The results are compelling and the code to compute them is actually straightforward to write, but the paper that introduces it assumes a lot of background knowledge from the first time reader. This paper is an attempt to provide this background, add some insights into the “why” questions, and hopefully give you all you need to add SH lighting to your game.},
author = {Green, Robin},
doi = {10.1090/S0025-5718-03-01597-7},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/spherical-harmonic-lighting.pdf:pdf},
issn = {19326203},
journal = {Archives of the Game Developers Conference},
pmid = {20020061},
title = {{Spherical harmonic lighting: The gritty details}},
url = {http://www.cs.columbia.edu/~cs4162/slides/spherical-harmonic-lighting.pdf},
year = {2003}
}
@article{Wong1997,
abstract = {The Hammersley and Halton point sets, two well known low discrepancy sequences, have been used for quasi-Monte Carlo integration in previous research. A deterministic formula generates a uniformly distributed and stochastic-looking sampling pattern, at low computational cost. The Halton point set is also useful for incremental sampling. In this paper, we discuss detailed implementation issues and our experience of choosing suitable bases of the point sets, not just on the 2D plane, but also on a spherical surface. The sampling scheme is also applied to ray tracing, with a significant improvement in error.},
author = {Wong, Tien-Tsin and Luk, Wai-Shing and Heng, Pheng-Ann},
doi = {10.1080/10867651.1997.10487471},
file = {:D$\backslash$:/Google Drive/Paper/Sampling with Hammersley and Halton Points.pdf:pdf},
issn = {1086-7651},
journal = {Journal of Graphics Tools},
pages = {9--24},
title = {{Sampling with Hammersley and Halton Points}},
volume = {2},
year = {1997}
}
@article{Green2007,
abstract = {A simple and efficient method is presented which allows improved rendering of glyphs composed of curved and linear elements. A distance field is generated from a high resolution image, and then stored into a channel of a lower-resolution texture. In the simplest case, this texture can then be rendered simply by using the alpha-testing and alpha-thresholding feature of modern GPUs, without a custom shader. This allows the technique to be used on even the lowest-end 3D graphics hardware. With the use of programmable shading, the technique is extended to perform various special effect renderings, including soft edges, outlining, drop shadows, multi-colored images, and sharp corners.},
author = {Green, Chris},
doi = {10.1145/1281500.1281665},
file = {:E$\backslash$:/Dev/hs/yage-meta/yage-research/papers/SIGGRAPH2007\_AlphaTestedMagnification.pdf:pdf},
isbn = {9781450318235},
journal = {ACM SIGGRAPH 2007 courses on - SIGGRAPH '07},
pages = {9},
title = {{Improved alpha-tested magnification for vector textures and special effects}},
url = {http://dl.acm.org/citation.cfm?doid=1281500.1281665},
year = {2007}
}
@article{Crassin2011b,
abstract = {In this thesis, we present a new approach to efficiently render large scenes and detailed objects in real- time. Our approach is based on a new volumetric prefiltered geometry representation and an asso- ciated voxel-based approximate cone tracing that allows an accurate and high performance rendering with high quality filtering of highly detailed geometry. In order to bring this voxel representation as a standard real-time rendering primitive, we propose a new GPU-based approach designed to entirely scale to the rendering of very large volumetric datasets. Our system achieves real-time rendering performance for several billion voxels. Our data structure exploits the fact that in CG scenes, details are often concentrated on the interface between free space and clusters of density and shows that volumetric models might become a valuable alternative as a rendering primitive for real-time applications. In this spirit, we allow a quality performance trade-of and exploit temporal coherence. Our solution is based on an adaptive hierarchical data representation depending on the current view and occlusion information, coupled to an efficient ray-casting rendering algorithm. We introduce a new GPU cache mechanism providing a very efficient paging of data in video memory and imple- mented as a very efficient data-parallel process. This cache is coupled with a data production pipeline able to dynamically load or produce voxel data directly on the GPU. One key element of our method is to guide data production and caching in video memory directly based on data requests and usage information emitted directly during rendering. We demonstrate our approach with several applications. We also show how our pre-filtered geometry model and approximate cone tracing can be used to very efficiently achieve blurry effects and real-time indirect lighting.},
author = {Crassin, Cyril},
file = {:D$\backslash$:/Google Drive/Paper/octree\_CCrassinThesis\_EN\_Web.pdf:pdf},
journal = {Thesis},
pages = {207},
title = {{GigaVoxels: A Voxel-Based Rendering Pipeline For Efficient Exploration Of Large And Detailed Scenes}},
url = {http://artis.imag.fr/Publications/2011/Cra11/CCrassinThesis\_EN\_Web.pdf},
year = {2011}
}
@inproceedings{panteleev-2014,
abstract = {This session describes the work at making the voxel-based global illumination (GI) approach practical for use in games running on current generation graphics hardware such as Kepler. Based upon Cyril Crassin's research, a library has been developed that allows applications to render GI effects for large and fully dynamic scenes at 30 frames per second or more, producing soft diffuse indirect lighting and blurry specular reflections, and providing emissive material support. During the session, Alexey will talk about the cone tracing GI algorithm in general and get into the details of scene representation, efficient multi-resolution voxelization, and indirect light gathering. - See more at: http://www.nvidia.com/object/siggraph2014-best-gtc.html\#sthash.da63WT5r.dpuf},
annote = {http://on-demand.gputechconf.com/gtc/2014/presentations/S4552-rt-voxel-based-global-illumination-gpus.pdf},
author = {Panteleev, Alexey},
keywords = { real-time, voxel,global illumination},
title = {{Practical Real-Time Voxel-Based Global Illumination for Current GPUs}},
year = {214}
}
@url{cryenginesdk:lighting,
author = {Johnson, Adam},
keywords = { global illumination, shadows, static lighting,dynamic lighting},
title = {{Static vs. Dynamic Lighting}},
url = {http://docs.cryengine.com/display/SDKDOC4/Static+vs.+Dynamic+Lighting}
}
@misc{Naylor1993,
author = {Naylor, Bruce},
keywords = {data structure,tree},
title = {{Constructing Good Partitioning Trees}},
url = {http://www.graphicsinterface.org/pre1996/93-Naylor.pdf},
year = {1993}
}
@inproceedings{ClusteredShading2012,
abstract = {
This paper presents and investigates Clustered Shading for deferred
and forward rendering. In Clustered Shading, view samples with similar
properties (e.g. 3D-position and/or normal) are grouped into clusters.
This is comparable to tiled shading, where view samples are grouped
into tiles based on 2D-position only. We show that Clustered Shading
creates a better mapping of light sources to view samples than tiled
shading, resulting in a significant reduction of lighting computations
during shading. Additionally, Clustered Shading enables using normal
information to perform per-cluster back-face culling of lights, again
reducing the number of lighting computations. We also show that
Clustered Shading not only outperforms tiled shading in many scenes,
but also exhibits better worst case behaviour under tricky conditions
(e.g. when looking at high-frequency geometry with large
discontinuities in depth). Additionally, Clustered Shading enables
real-time scenes with two to three orders of magnitudes more lights
than previously feasible (up to around one million light sources).},
author = {Olsson, Ola and Billeter, Markus and Assarsson, Ulf},
booktitle = {HPG '12: Proceedings of the Conference on High Performance Graphics 2012},
title = {{Clustered Deferred and Forward Shading}},
year = {2012}
}
@inproceedings{rousiers-2014,
author = {de Rousiers, Charles and Lagarde, S\'{e}bastian},
keywords = {physically based rendering},
series = {SIGGRAPH 2014},
title = {{Moving to physically based rendering}},
year = {2014}
}
@phdthesis{James1999,
author = {James, Adam},
keywords = {data structure},
school = {University of East Anglia},
title = {{Binary Space Partitioning for Accelerated Hidden Surface Removal and Rendering of Static Environments}},
url = {http://erich.realtimerendering.com/bsp/aj.pdf},
year = {1999}
}
@article{Mealy1955,
author = {Mealy, Gh},
journal = {Bell System Technical Journal},
keywords = {2000 book nlp},
number = {5},
pages = {1045--1079},
title = {{A method for synthesizing sequential circuits}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/j.1538-7305.1955.tb03788.x/abstract},
volume = {34},
year = {1955}
}
@book{Millington2007,
author = {Millington, Ian},
keywords = { software architecture,game engine},
publisher = {Morgan Kaufmann},
title = {{Game Physics Engine Development (The Morgan Kaufmann Series in Interactive 3D Technology)}},
year = {2007}
}
@book{Gamma2004-07-31,
author = {Gamma, "Erich and Helm, Richard and Johnson, Ralph and Vlissides", John},
keywords = {design patterns,software,software architecture},
publisher = {Addison Wesley Verlag},
title = {{Entwurfsmuster: Elemente wiederverwendbarer objektorientierter Software}},
year = {2004}
}
@misc{bohn:gamephysics,
author = {Bohn, C.-A.},
keywords = {game engine,physics},
title = {{Game-Physics}},
url = {http://www.fh-wedel.de/~bo/db/handouts/public/ss08/gamephysics2.pdf},
year = {2008}
}
@url{gamedevnet:glnext,
author = {Promit},
keywords = { direct x, mantle, opengl, vulkan,modern graphics},
title = {{Opinion about Vulkan/Mantle/Direct X 12}},
url = {http://www.gamedev.net/topic/666419-what-are-your-opinions-on-dx12vulkanmantle/\#entry5215019}
}
@book{Lengyel2003,
author = {Lengyel, Eric},
keywords = {game programming,mathematics},
publisher = {Charles River Media},
title = {{Mathematics for 3D Game Programming and Computer Graphics (Charles River Media Game Development)}},
year = {2003}
}
@inproceedings{crassin2011interactive,
author = {Crassin, Cyril and Neyret, Fabrice and Sainz, Miguel and Green, Simon and Eisemann, Elmar},
booktitle = {Computer Graphics Forum},
keywords = {cone tracing,global illumination,lighting,voxel},
number = {7},
organization = {Wiley Online Library},
pages = {1921--1930},
title = {{Interactive indirect illumination using voxel cone tracing}},
volume = {30},
year = {2011}
}
@book{Ericson2005,
author = {Ericson, Christer},
keywords = {collision detection,physics},
publisher = {Morgan Kaufmann},
title = {{Real-Time Collision Detection (The Morgan Kaufmann Series in Interactive 3D Technology)}},
year = {2005}
}
@webpage{ogl-sparse-2013,
author = {Sellers, Graham},
keywords = {opengl,texturing},
title = {{ARB Sparse Texture}},
url = {https://www.opengl.org/registry/specs/ARB/sparse\_texture.txt},
year = {2013}
}
@inproceedings{olsson:Shadows:2014,
abstract = {Recently, several algorithms have been introduced that enable real-time performance for many lights in applications such as games. In this paper, we explore the use of 
hardware-supported virtual cube-map shadows to efficiently implement high-quality shadows from hundreds of light sources in real time and within a bounded memory footprint. 
In addition, we explore the utility of ray tracing for shadows from many lights and present a hybrid algorithm combining ray tracing with cube maps to exploit their respective 
strengths. Our solution supports real-time performance with hundreds of lights in fully dynamic high-detail scenes.},
author = {Olsson, Ola and Sintorn, Erik and K\"{a}mpe, Viktor and Billeter, Markus and Assarsson, Ulf},
booktitle = {Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
keywords = {cubemap,real-time,shadows,texturing,virtual},
publisher = {ACM},
title = {{Efficient Virtual Shadow Maps for Many Lights}},
year = {2014}
}
@article{kaplanyan2009light,
author = {Kaplanyan, Anton},
journal = {ACM SIGGRAPH Courses},
keywords = {global illumination,lighting,volumes},
pages = {2},
title = {{Light propagation volumes in cryengine 3}},
volume = {7},
year = {2009}
}
